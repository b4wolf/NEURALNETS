{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/b4wolf/NEURALNETS/blob/development/working_copy_PMWeather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "FZP7PnZt86En"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "json_folder = 'WI_weather_coords'\n",
        "csv_folder = 'clean_WI_data'\n",
        "\n",
        "weather_dict = {}\n",
        "\n",
        "for filename in os.listdir(json_folder):\n",
        "    if filename.endswith('.json'):\n",
        "        with open(os.path.join(json_folder, filename), 'r') as f:\n",
        "            data = json.load(f)\n",
        "            prefix = filename.split('.')[0]\n",
        "            weather_dict[prefix] = data['lat_lon']\n",
        "\n",
        "\n",
        "json_folder = './WI_weather_coords'\n",
        "csv_folder = './clean_WI_data'\n",
        "\n",
        "weather_data_mapping = {}\n",
        "\n",
        "for json_filename in os.listdir(json_folder):\n",
        "    if json_filename.endswith('.json'):\n",
        "        prefix = json_filename.split('.')[0]\n",
        "        json_path = os.path.join(json_folder, json_filename)\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            lat_lon = data['lat_lon']\n",
        "\n",
        "            if prefix not in weather_data_mapping:\n",
        "                weather_data_mapping[prefix] = {'lat_lon': None, 'csv_path': None}\n",
        "\n",
        "            weather_data_mapping[prefix]['lat_lon'] = lat_lon\n",
        "\n",
        "for csv_filename in os.listdir(csv_folder):\n",
        "    if csv_filename.endswith('.csv'):\n",
        "        prefix = csv_filename.split('.')[0]\n",
        "\n",
        "        if prefix in weather_data_mapping:\n",
        "            csv_path = os.path.join(csv_folder, csv_filename)\n",
        "            weather_data_mapping[prefix]['csv_path'] = csv_path\n",
        "\n",
        "\n",
        "lat_lon_mapping = {}\n",
        "\n",
        "for json_filename in os.listdir(json_folder):\n",
        "    if json_filename.endswith('.json'):\n",
        "        prefix = json_filename.split('.')[0]\n",
        "        json_path = os.path.join(json_folder, json_filename)\n",
        "        with open(json_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            lat_lon_mapping[prefix] = data['lat_lon']\n",
        "\n",
        "weather_data = {}\n",
        "\n",
        "for csv_filename in os.listdir(csv_folder):\n",
        "    if csv_filename.endswith('.csv'):\n",
        "        prefix = csv_filename.split('.')[0]\n",
        "\n",
        "        if prefix in lat_lon_mapping:\n",
        "            csv_path = os.path.join(csv_folder, csv_filename)\n",
        "\n",
        "            df = pd.read_csv(csv_path)\n",
        "\n",
        "            df['latitude'] = lat_lon_mapping[prefix][0]\n",
        "            df['longitude'] = lat_lon_mapping[prefix][1]\n",
        "\n",
        "            weather_data[prefix] = df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import regex as re\n",
        "directory_path = '/content/'\n",
        "file_names = [file for file in os.listdir(directory_path) if 'monitor' in file and file.endswith('.csv')]\n",
        "data_frames = []\n",
        "\n",
        "for file_name in file_names:\n",
        "    match = re.match(r'processed_monitor_([0-9.-]+)_([0-9.-]+)\\.csv', file_name)\n",
        "    if match:\n",
        "        lat, lon = match.groups()\n",
        "        lat, lon = float(lat), float(lon)\n",
        "        try:\n",
        "            df = pd.read_csv(os.path.join(directory_path, file_name))\n",
        "            df['Latitude'] = lat\n",
        "            df['Longitude'] = lon\n",
        "            data_frames.append(df)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"File not found: {file_name}\")\n",
        "        except pd.errors.EmptyDataError:\n",
        "            print(f\"No data in file: {file_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file_name}: {e}\")\n",
        "    else:\n",
        "        print(f\"Filename pattern mismatch: {file_name}\")"
      ],
      "metadata": {
        "id": "6AjyCrw0ZHrF"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wet_lat_lon = []\n",
        "pm_lat_lon = []\n",
        "for df in weather_data:\n",
        "  wet_lat_lon.append((weather_data[df]['longitude'][0], weather_data[df]['latitude'][0]))\n",
        "\n",
        "for index, df in enumerate(data_frames):\n",
        "  pm_lat_lon.append((df['Latitude'][0], df['Longitude'][0]))"
      ],
      "metadata": {
        "id": "KvdsUIHnbPYh"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import radians, sin, cos, sqrt, atan2\n",
        "\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
        "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "    distance = 6371 * c\n",
        "\n",
        "    return distance\n",
        "\n",
        "#########################################\n",
        "# Finds the nearest neighbors between\n",
        "# weather and PM 2.5 stations\n",
        "#########################################\n",
        "def find_nearest_neighbors(list1, list2):\n",
        "    nearest_neighbors = []\n",
        "\n",
        "    for point1 in list1:\n",
        "        min_distance = float('inf')\n",
        "        nearest_neighbor = None\n",
        "\n",
        "        for point2 in list2:\n",
        "            distance = haversine(point1[0], point1[1], point2[0], point2[1])\n",
        "            if distance < min_distance:\n",
        "                min_distance = distance\n",
        "                nearest_neighbor = point2\n",
        "        nearest_neighbors.append((point1, nearest_neighbor, min_distance))\n",
        "\n",
        "    return nearest_neighbors\n",
        "\n",
        "list1 = pm_lat_lon\n",
        "list2 = wet_lat_lon\n",
        "\n",
        "nearest_neighbors = find_nearest_neighbors(list1, list2)\n",
        "\n",
        "for index, n in enumerate(nearest_neighbors):\n",
        "  nearest_neighbors[index] = (pm_lat_lon.index(n[0]), wet_lat_lon.index(n[1]), n[2])\n",
        "  data_frames[nearest_neighbors[index][0]] = pd.concat([data_frames[nearest_neighbors[index][0]], weather_data[list(weather_data.keys())[nearest_neighbors[index][1]]]], axis=1)\n",
        "\n",
        "# cleaning the dataframe to only get the information we need\n",
        "prepped_data_frames = []\n",
        "for df in data_frames:\n",
        "  df = df.drop('Unnamed: 0', axis=1) \\\n",
        "    .drop('latitude', axis=1) \\\n",
        "    .drop('longitude', axis=1) \\\n",
        "    .drop('Index', axis=1) \\\n",
        "    .rename(columns={'Value': 'pm25'})\n",
        "  prepped_data_frames.append(df)\n",
        "\n",
        "\n",
        "#########################################\n",
        "# Finds edges between stations\n",
        "#########################################\n",
        "\n",
        "G = nx.Graph()\n",
        "distances = {}\n",
        "node_positions = {}\n",
        "\n",
        "for i in range(len(data_frames)):\n",
        "    coord1 = (prepped_data_frames[i]['Latitude'].iloc[0], prepped_data_frames[i]['Longitude'].iloc[0])\n",
        "    node_positions[i] = coord1\n",
        "    distances[i] = []\n",
        "\n",
        "    for j in range(len(data_frames)):\n",
        "        if i != j:\n",
        "            coord2 = (prepped_data_frames[j]['Latitude'].iloc[0], prepped_data_frames[j]['Longitude'].iloc[0])\n",
        "            distance = haversine(coord1[0], coord1[1], coord2[0], coord2[1])\n",
        "            distances[i].append((distance, j))\n",
        "\n",
        "for i, dist_list in distances.items():\n",
        "    three_nearest = nsmallest(3, dist_list)\n",
        "    for dist, j in three_nearest:\n",
        "        G.add_edge(i, j, weight=dist)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "nx.draw(G, pos=node_positions, with_labels=True, node_size=50, node_color=\"skyblue\", edge_color=\"gray\")\n",
        "plt.title(\"Station Graph\")\n",
        "plt.show()\n",
        "list(G.edges())"
      ],
      "metadata": {
        "id": "wn69Ov5zaykl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adj_mat = nx.adjacency_matrix(G)"
      ],
      "metadata": {
        "id": "2ZId_r5STAwH"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "9YTU6XRx3qRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import folium\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import SAGEConv\n",
        "from scipy.spatial.distance import euclidean\n",
        "import os\n",
        "import networkx as nx\n",
        "from torch_geometric.data import Data\n",
        "import math\n",
        "from heapq import nsmallest\n",
        "import pandas as pd\n",
        "import re\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import scipy.sparse as sparse"
      ],
      "metadata": {
        "id": "Wti7D8mv3ozo"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse.csr_matrix(adj_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4RHKINgUxnz",
        "outputId": "1fad6eb3-738a-464b-e562-dfe527a20cea"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 46 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stat_train_predictions = []\n",
        "stat_test_predictions = []\n",
        "\n",
        "for df in prepped_data_frames:\n",
        "  timeseries = df.drop('Latitude', axis=1).drop('Longitude', axis=1).values.astype('float32')\n",
        "  train_size = int(len(timeseries) * 0.70)\n",
        "  test_size = len(timeseries) - train_size\n",
        "  train, test = timeseries[:train_size], timeseries[train_size:]\n",
        "\n",
        "  def create_dataset(dataset, lookback):\n",
        "      \"\"\"Transform a time series into a prediction dataset\n",
        "\n",
        "      Args:\n",
        "          dataset: A numpy array of time series, first dimension is the time steps\n",
        "          lookback: Size of window for prediction\n",
        "      \"\"\"\n",
        "      X, y = [], []\n",
        "      for i in range(len(dataset)-lookback):\n",
        "          feature = dataset[i:i+lookback]\n",
        "          target = dataset[i+1:i+lookback+1]\n",
        "          X.append(feature)\n",
        "          y.append(target)\n",
        "      return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "  lookback = 7\n",
        "  X_train, y_train = create_dataset(train, lookback=lookback)\n",
        "  X_test, y_test = create_dataset(test, lookback=lookback)\n",
        "  class AirModel(nn.Module):\n",
        "      def __init__(self):\n",
        "          super().__init__()\n",
        "          self.lstm = nn.LSTM(input_size=9, hidden_size=50, num_layers=1, batch_first=True)\n",
        "          self.linear = nn.Linear(50, 9)\n",
        "      def forward(self, x):\n",
        "          x, _ = self.lstm(x)\n",
        "          x = self.linear(x)\n",
        "          return x\n",
        "\n",
        "  model = AirModel()\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  loss_fn = nn.MSELoss()\n",
        "  loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=8)\n",
        "\n",
        "  n_epochs = 100\n",
        "  for epoch in range(n_epochs):\n",
        "      model.train()\n",
        "      losses = []\n",
        "      for X_batch, y_batch in loader:\n",
        "          y_pred = model(X_batch)\n",
        "          loss = loss_fn(y_pred, y_batch)\n",
        "          losses.append(loss.detach().numpy())\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      # Validation\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "          y_pred = model(X_train)\n",
        "          train_rmse = np.sqrt(loss_fn(y_pred, y_train))\n",
        "          y_pred = model(X_test)\n",
        "          test_rmse = np.sqrt(loss_fn(y_pred, y_test))\n",
        "      print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))\n",
        "\n",
        "  with torch.no_grad():\n",
        "    y_pred = model(X_train)\n",
        "    stat_train_predictions.append(y_pred[:, -1, :])\n",
        "    y_pred = model(X_test)\n",
        "    stat_test_predictions.append(y_pred[:, -1, :])\n",
        "\n",
        "  \"\"\"with torch.no_grad():\n",
        "      # shift train predictions for plotting\n",
        "      train_plot = np.ones_like(timeseries) * np.nan\n",
        "      y_pred = model(X_train)\n",
        "      y_pred = y_pred[:, -1, :]\n",
        "      print(y_pred.shape)\n",
        "      train_plot[lookback:train_size] = y_pred[:, 8]\n",
        "\n",
        "      # shift test predictions for plotting\n",
        "      test_plot = np.ones_like(timeseries) * np.nan\n",
        "      test_plot[train_size+lookback:len(timeseries)] = model(X_test)[:, -1, 8]\"\"\"\n",
        "\n",
        "\"\"\"  # plot\n",
        "  plt.plot(timeseries[:, 8])\n",
        "  plt.plot(train_plot, c='r')\n",
        "  plt.plot(test_plot, c='g')\n",
        "  plt.show()\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3FkmejRbrOaT",
        "outputId": "c0ef1a26-229b-4bc3-d9db-9c879484ecd2"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: train RMSE 59.4899, test RMSE 58.6489\n",
            "Epoch 1: train RMSE 51.1951, test RMSE 50.5570\n",
            "Epoch 2: train RMSE 45.8863, test RMSE 45.2804\n",
            "Epoch 3: train RMSE 41.8865, test RMSE 41.2131\n",
            "Epoch 4: train RMSE 38.6746, test RMSE 37.9637\n",
            "Epoch 5: train RMSE 36.0135, test RMSE 35.2367\n",
            "Epoch 6: train RMSE 33.7814, test RMSE 32.9782\n",
            "Epoch 7: train RMSE 31.7209, test RMSE 30.8539\n",
            "Epoch 8: train RMSE 30.1168, test RMSE 29.3411\n",
            "Epoch 9: train RMSE 28.8104, test RMSE 28.0957\n",
            "Epoch 10: train RMSE 27.7456, test RMSE 27.1332\n",
            "Epoch 11: train RMSE 26.9281, test RMSE 26.5209\n",
            "Epoch 12: train RMSE 26.4243, test RMSE 26.0660\n",
            "Epoch 13: train RMSE 25.8736, test RMSE 25.8399\n",
            "Epoch 14: train RMSE 25.4926, test RMSE 25.5892\n",
            "Epoch 15: train RMSE 25.1989, test RMSE 25.3809\n",
            "Epoch 16: train RMSE 24.9736, test RMSE 25.2179\n",
            "Epoch 17: train RMSE 24.7795, test RMSE 25.0549\n",
            "Epoch 18: train RMSE 24.5762, test RMSE 25.0146\n",
            "Epoch 19: train RMSE 24.4911, test RMSE 25.0268\n",
            "Epoch 20: train RMSE 24.5016, test RMSE 25.0141\n",
            "Epoch 21: train RMSE 24.3508, test RMSE 24.9238\n",
            "Epoch 22: train RMSE 24.2338, test RMSE 24.9395\n",
            "Epoch 23: train RMSE 24.1639, test RMSE 24.7919\n",
            "Epoch 24: train RMSE 24.0376, test RMSE 24.7148\n",
            "Epoch 25: train RMSE 24.0668, test RMSE 24.7298\n",
            "Epoch 26: train RMSE 23.9995, test RMSE 24.6814\n",
            "Epoch 27: train RMSE 23.8839, test RMSE 24.5871\n",
            "Epoch 28: train RMSE 23.9276, test RMSE 24.6609\n",
            "Epoch 29: train RMSE 23.8484, test RMSE 24.6059\n",
            "Epoch 30: train RMSE 23.7839, test RMSE 24.5755\n",
            "Epoch 31: train RMSE 23.9089, test RMSE 24.7237\n",
            "Epoch 32: train RMSE 23.8007, test RMSE 24.5504\n",
            "Epoch 33: train RMSE 23.7065, test RMSE 24.5156\n",
            "Epoch 34: train RMSE 23.7792, test RMSE 24.6149\n",
            "Epoch 35: train RMSE 23.6915, test RMSE 24.5142\n",
            "Epoch 36: train RMSE 23.6600, test RMSE 24.4659\n",
            "Epoch 37: train RMSE 23.7873, test RMSE 24.5237\n",
            "Epoch 38: train RMSE 23.5981, test RMSE 24.4572\n",
            "Epoch 39: train RMSE 23.5828, test RMSE 24.4991\n",
            "Epoch 40: train RMSE 23.6005, test RMSE 24.5277\n",
            "Epoch 41: train RMSE 23.5580, test RMSE 24.5137\n",
            "Epoch 42: train RMSE 23.5112, test RMSE 24.4267\n",
            "Epoch 43: train RMSE 23.4885, test RMSE 24.3954\n",
            "Epoch 44: train RMSE 23.4827, test RMSE 24.4274\n",
            "Epoch 45: train RMSE 23.5301, test RMSE 24.4259\n",
            "Epoch 46: train RMSE 23.5178, test RMSE 24.5182\n",
            "Epoch 47: train RMSE 23.4708, test RMSE 24.4168\n",
            "Epoch 48: train RMSE 23.4094, test RMSE 24.3155\n",
            "Epoch 49: train RMSE 23.4038, test RMSE 24.5044\n",
            "Epoch 50: train RMSE 23.4576, test RMSE 24.4945\n",
            "Epoch 51: train RMSE 23.4758, test RMSE 24.4988\n",
            "Epoch 52: train RMSE 23.3904, test RMSE 24.3699\n",
            "Epoch 53: train RMSE 23.2785, test RMSE 24.3870\n",
            "Epoch 54: train RMSE 23.3136, test RMSE 24.4251\n",
            "Epoch 55: train RMSE 23.3355, test RMSE 24.4331\n",
            "Epoch 56: train RMSE 23.2659, test RMSE 24.3803\n",
            "Epoch 57: train RMSE 23.2752, test RMSE 24.4205\n",
            "Epoch 58: train RMSE 23.2868, test RMSE 24.3650\n",
            "Epoch 59: train RMSE 23.2627, test RMSE 24.4280\n",
            "Epoch 60: train RMSE 23.1616, test RMSE 24.3586\n",
            "Epoch 61: train RMSE 23.2866, test RMSE 24.4074\n",
            "Epoch 62: train RMSE 23.2114, test RMSE 24.4764\n",
            "Epoch 63: train RMSE 23.1988, test RMSE 24.4148\n",
            "Epoch 64: train RMSE 23.1582, test RMSE 24.3970\n",
            "Epoch 65: train RMSE 23.2150, test RMSE 24.3893\n",
            "Epoch 66: train RMSE 23.1326, test RMSE 24.3352\n",
            "Epoch 67: train RMSE 23.1382, test RMSE 24.4170\n",
            "Epoch 68: train RMSE 23.1382, test RMSE 24.3392\n",
            "Epoch 69: train RMSE 23.1670, test RMSE 24.3640\n",
            "Epoch 70: train RMSE 23.1583, test RMSE 24.4128\n",
            "Epoch 71: train RMSE 23.0926, test RMSE 24.3327\n",
            "Epoch 72: train RMSE 23.0493, test RMSE 24.3987\n",
            "Epoch 73: train RMSE 23.0602, test RMSE 24.3352\n",
            "Epoch 74: train RMSE 23.0593, test RMSE 24.3680\n",
            "Epoch 75: train RMSE 23.1055, test RMSE 24.3376\n",
            "Epoch 76: train RMSE 22.9790, test RMSE 24.3426\n",
            "Epoch 77: train RMSE 23.0141, test RMSE 24.3683\n",
            "Epoch 78: train RMSE 23.0466, test RMSE 24.3575\n",
            "Epoch 79: train RMSE 23.1117, test RMSE 24.3677\n",
            "Epoch 80: train RMSE 23.0184, test RMSE 24.4219\n",
            "Epoch 81: train RMSE 23.0049, test RMSE 24.3780\n",
            "Epoch 82: train RMSE 23.0713, test RMSE 24.4007\n",
            "Epoch 83: train RMSE 22.9664, test RMSE 24.3033\n",
            "Epoch 84: train RMSE 22.9056, test RMSE 24.3883\n",
            "Epoch 85: train RMSE 23.0172, test RMSE 24.3293\n",
            "Epoch 86: train RMSE 22.8803, test RMSE 24.3398\n",
            "Epoch 87: train RMSE 22.8963, test RMSE 24.3600\n",
            "Epoch 88: train RMSE 22.9020, test RMSE 24.3831\n",
            "Epoch 89: train RMSE 22.9243, test RMSE 24.3916\n",
            "Epoch 90: train RMSE 22.9791, test RMSE 24.4399\n",
            "Epoch 91: train RMSE 22.9049, test RMSE 24.3242\n",
            "Epoch 92: train RMSE 22.8996, test RMSE 24.3460\n",
            "Epoch 93: train RMSE 22.8605, test RMSE 24.3944\n",
            "Epoch 94: train RMSE 22.8972, test RMSE 24.3666\n",
            "Epoch 95: train RMSE 22.8705, test RMSE 24.3369\n",
            "Epoch 96: train RMSE 22.9387, test RMSE 24.3658\n",
            "Epoch 97: train RMSE 22.9145, test RMSE 24.4277\n",
            "Epoch 98: train RMSE 22.8159, test RMSE 24.3481\n",
            "Epoch 99: train RMSE 22.8412, test RMSE 24.4361\n",
            "Epoch 0: train RMSE 54.5248, test RMSE 55.6928\n",
            "Epoch 1: train RMSE 48.0321, test RMSE 49.0536\n",
            "Epoch 2: train RMSE 44.1731, test RMSE 44.7264\n",
            "Epoch 3: train RMSE 41.4035, test RMSE 41.4268\n",
            "Epoch 4: train RMSE 39.3386, test RMSE 38.8827\n",
            "Epoch 5: train RMSE 37.5202, test RMSE 36.6184\n",
            "Epoch 6: train RMSE 35.8744, test RMSE 34.6249\n",
            "Epoch 7: train RMSE 34.5255, test RMSE 32.9930\n",
            "Epoch 8: train RMSE 33.3997, test RMSE 31.7061\n",
            "Epoch 9: train RMSE 32.4983, test RMSE 30.6702\n",
            "Epoch 10: train RMSE 31.7030, test RMSE 29.8523\n",
            "Epoch 11: train RMSE 31.1617, test RMSE 29.2741\n",
            "Epoch 12: train RMSE 30.6703, test RMSE 28.8823\n",
            "Epoch 13: train RMSE 30.3680, test RMSE 28.6171\n",
            "Epoch 14: train RMSE 30.1899, test RMSE 28.4590\n",
            "Epoch 15: train RMSE 29.8536, test RMSE 28.1700\n",
            "Epoch 16: train RMSE 29.7033, test RMSE 28.0726\n",
            "Epoch 17: train RMSE 29.5751, test RMSE 28.1224\n",
            "Epoch 18: train RMSE 29.4409, test RMSE 27.8979\n",
            "Epoch 19: train RMSE 29.3998, test RMSE 28.0622\n",
            "Epoch 20: train RMSE 29.2569, test RMSE 27.8382\n",
            "Epoch 21: train RMSE 29.0787, test RMSE 27.7198\n",
            "Epoch 22: train RMSE 29.0396, test RMSE 27.7059\n",
            "Epoch 23: train RMSE 28.9898, test RMSE 27.7266\n",
            "Epoch 24: train RMSE 28.8356, test RMSE 27.6766\n",
            "Epoch 25: train RMSE 28.8335, test RMSE 27.5493\n",
            "Epoch 26: train RMSE 28.7822, test RMSE 27.6450\n",
            "Epoch 27: train RMSE 28.8692, test RMSE 27.5155\n",
            "Epoch 28: train RMSE 28.5833, test RMSE 27.5090\n",
            "Epoch 29: train RMSE 28.6443, test RMSE 27.6315\n",
            "Epoch 30: train RMSE 28.5593, test RMSE 27.4865\n",
            "Epoch 31: train RMSE 28.4689, test RMSE 27.4470\n",
            "Epoch 32: train RMSE 28.5331, test RMSE 27.5206\n",
            "Epoch 33: train RMSE 28.3668, test RMSE 27.4503\n",
            "Epoch 34: train RMSE 28.4858, test RMSE 27.5241\n",
            "Epoch 35: train RMSE 28.3430, test RMSE 27.4496\n",
            "Epoch 36: train RMSE 28.3330, test RMSE 27.4811\n",
            "Epoch 37: train RMSE 28.1966, test RMSE 27.3928\n",
            "Epoch 38: train RMSE 28.2579, test RMSE 27.4491\n",
            "Epoch 39: train RMSE 28.2493, test RMSE 27.4164\n",
            "Epoch 40: train RMSE 28.2094, test RMSE 27.5083\n",
            "Epoch 41: train RMSE 28.1573, test RMSE 27.4660\n",
            "Epoch 42: train RMSE 28.0632, test RMSE 27.3876\n",
            "Epoch 43: train RMSE 28.1155, test RMSE 27.3875\n",
            "Epoch 44: train RMSE 28.0642, test RMSE 27.3914\n",
            "Epoch 45: train RMSE 27.9919, test RMSE 27.4041\n",
            "Epoch 46: train RMSE 27.9136, test RMSE 27.3989\n",
            "Epoch 47: train RMSE 27.9815, test RMSE 27.3183\n",
            "Epoch 48: train RMSE 27.8863, test RMSE 27.3644\n",
            "Epoch 49: train RMSE 27.8699, test RMSE 27.3683\n",
            "Epoch 50: train RMSE 27.8530, test RMSE 27.5141\n",
            "Epoch 51: train RMSE 27.8138, test RMSE 27.4453\n",
            "Epoch 52: train RMSE 27.9877, test RMSE 27.4828\n",
            "Epoch 53: train RMSE 27.8113, test RMSE 27.4541\n",
            "Epoch 54: train RMSE 27.7831, test RMSE 27.4017\n",
            "Epoch 55: train RMSE 27.8275, test RMSE 27.4788\n",
            "Epoch 56: train RMSE 27.7158, test RMSE 27.4440\n",
            "Epoch 57: train RMSE 27.7678, test RMSE 27.4576\n",
            "Epoch 58: train RMSE 27.6703, test RMSE 27.4675\n",
            "Epoch 59: train RMSE 27.6032, test RMSE 27.4950\n",
            "Epoch 60: train RMSE 27.6006, test RMSE 27.4505\n",
            "Epoch 61: train RMSE 27.5717, test RMSE 27.4483\n",
            "Epoch 62: train RMSE 27.5292, test RMSE 27.4082\n",
            "Epoch 63: train RMSE 27.5225, test RMSE 27.4471\n",
            "Epoch 64: train RMSE 27.5241, test RMSE 27.5029\n",
            "Epoch 65: train RMSE 27.5333, test RMSE 27.4937\n",
            "Epoch 66: train RMSE 27.5946, test RMSE 27.5001\n",
            "Epoch 67: train RMSE 27.4731, test RMSE 27.5132\n",
            "Epoch 68: train RMSE 27.4817, test RMSE 27.5618\n",
            "Epoch 69: train RMSE 27.3335, test RMSE 27.5037\n",
            "Epoch 70: train RMSE 27.5112, test RMSE 27.6022\n",
            "Epoch 71: train RMSE 27.4345, test RMSE 27.5654\n",
            "Epoch 72: train RMSE 27.3956, test RMSE 27.5666\n",
            "Epoch 73: train RMSE 27.3477, test RMSE 27.6027\n",
            "Epoch 74: train RMSE 27.3638, test RMSE 27.6021\n",
            "Epoch 75: train RMSE 27.3834, test RMSE 27.6409\n",
            "Epoch 76: train RMSE 27.3087, test RMSE 27.5638\n",
            "Epoch 77: train RMSE 27.2918, test RMSE 27.5202\n",
            "Epoch 78: train RMSE 27.2780, test RMSE 27.6794\n",
            "Epoch 79: train RMSE 27.3559, test RMSE 27.6494\n",
            "Epoch 80: train RMSE 27.1618, test RMSE 27.5983\n",
            "Epoch 81: train RMSE 27.2247, test RMSE 27.6175\n",
            "Epoch 82: train RMSE 27.1875, test RMSE 27.6475\n",
            "Epoch 83: train RMSE 27.2154, test RMSE 27.6183\n",
            "Epoch 84: train RMSE 27.1573, test RMSE 27.7171\n",
            "Epoch 85: train RMSE 27.2360, test RMSE 27.6227\n",
            "Epoch 86: train RMSE 27.1140, test RMSE 27.6179\n",
            "Epoch 87: train RMSE 27.1698, test RMSE 27.6242\n",
            "Epoch 88: train RMSE 27.0218, test RMSE 27.6308\n",
            "Epoch 89: train RMSE 26.9769, test RMSE 27.6446\n",
            "Epoch 90: train RMSE 27.0764, test RMSE 27.6583\n",
            "Epoch 91: train RMSE 27.1919, test RMSE 27.6966\n",
            "Epoch 92: train RMSE 27.0595, test RMSE 27.6694\n",
            "Epoch 93: train RMSE 27.0055, test RMSE 27.6780\n",
            "Epoch 94: train RMSE 26.9927, test RMSE 27.7747\n",
            "Epoch 95: train RMSE 27.0581, test RMSE 27.6561\n",
            "Epoch 96: train RMSE 27.0085, test RMSE 27.6312\n",
            "Epoch 97: train RMSE 26.8748, test RMSE 27.7129\n",
            "Epoch 98: train RMSE 26.9603, test RMSE 27.8044\n",
            "Epoch 99: train RMSE 26.9019, test RMSE 27.8246\n",
            "Epoch 0: train RMSE 63.0497, test RMSE 64.9598\n",
            "Epoch 1: train RMSE 53.5681, test RMSE 55.3364\n",
            "Epoch 2: train RMSE 47.5025, test RMSE 48.6923\n",
            "Epoch 3: train RMSE 43.2495, test RMSE 43.7633\n",
            "Epoch 4: train RMSE 39.9386, test RMSE 39.8492\n",
            "Epoch 5: train RMSE 37.1360, test RMSE 36.5066\n",
            "Epoch 6: train RMSE 35.1118, test RMSE 33.9323\n",
            "Epoch 7: train RMSE 33.4172, test RMSE 31.8148\n",
            "Epoch 8: train RMSE 31.7982, test RMSE 29.9292\n",
            "Epoch 9: train RMSE 30.1854, test RMSE 28.1504\n",
            "Epoch 10: train RMSE 28.9947, test RMSE 26.8205\n",
            "Epoch 11: train RMSE 27.9752, test RMSE 25.8383\n",
            "Epoch 12: train RMSE 27.2131, test RMSE 25.1578\n",
            "Epoch 13: train RMSE 26.4877, test RMSE 24.6155\n",
            "Epoch 14: train RMSE 25.9618, test RMSE 24.1895\n",
            "Epoch 15: train RMSE 25.6210, test RMSE 23.9743\n",
            "Epoch 16: train RMSE 25.2528, test RMSE 23.9074\n",
            "Epoch 17: train RMSE 24.8938, test RMSE 23.5950\n",
            "Epoch 18: train RMSE 24.7477, test RMSE 23.4708\n",
            "Epoch 19: train RMSE 24.5726, test RMSE 23.3662\n",
            "Epoch 20: train RMSE 24.4053, test RMSE 23.2266\n",
            "Epoch 21: train RMSE 24.3119, test RMSE 23.2403\n",
            "Epoch 22: train RMSE 24.2140, test RMSE 23.2838\n",
            "Epoch 23: train RMSE 24.0109, test RMSE 23.1756\n",
            "Epoch 24: train RMSE 23.9981, test RMSE 23.1610\n",
            "Epoch 25: train RMSE 23.9748, test RMSE 23.3277\n",
            "Epoch 26: train RMSE 23.9127, test RMSE 23.2685\n",
            "Epoch 27: train RMSE 23.8151, test RMSE 23.1676\n",
            "Epoch 28: train RMSE 23.6763, test RMSE 22.9961\n",
            "Epoch 29: train RMSE 23.7082, test RMSE 23.1195\n",
            "Epoch 30: train RMSE 23.6648, test RMSE 22.9572\n",
            "Epoch 31: train RMSE 23.6397, test RMSE 22.9300\n",
            "Epoch 32: train RMSE 23.5715, test RMSE 23.0658\n",
            "Epoch 33: train RMSE 23.6085, test RMSE 23.1261\n",
            "Epoch 34: train RMSE 23.4973, test RMSE 23.1125\n",
            "Epoch 35: train RMSE 23.5911, test RMSE 23.0170\n",
            "Epoch 36: train RMSE 23.5204, test RMSE 23.0122\n",
            "Epoch 37: train RMSE 23.4467, test RMSE 22.9977\n",
            "Epoch 38: train RMSE 23.4323, test RMSE 22.9602\n",
            "Epoch 39: train RMSE 23.4376, test RMSE 23.2081\n",
            "Epoch 40: train RMSE 23.4320, test RMSE 23.1321\n",
            "Epoch 41: train RMSE 23.3077, test RMSE 22.9586\n",
            "Epoch 42: train RMSE 23.3408, test RMSE 23.0829\n",
            "Epoch 43: train RMSE 23.3415, test RMSE 22.9354\n",
            "Epoch 44: train RMSE 23.2744, test RMSE 22.8656\n",
            "Epoch 45: train RMSE 23.3057, test RMSE 22.9500\n",
            "Epoch 46: train RMSE 23.3422, test RMSE 22.8778\n",
            "Epoch 47: train RMSE 23.1713, test RMSE 22.9578\n",
            "Epoch 48: train RMSE 23.1771, test RMSE 22.8598\n",
            "Epoch 49: train RMSE 23.1867, test RMSE 22.8770\n",
            "Epoch 50: train RMSE 23.1517, test RMSE 22.9288\n",
            "Epoch 51: train RMSE 23.1856, test RMSE 22.9393\n",
            "Epoch 52: train RMSE 23.1545, test RMSE 22.9473\n",
            "Epoch 53: train RMSE 23.1462, test RMSE 22.8818\n",
            "Epoch 54: train RMSE 23.1027, test RMSE 22.9541\n",
            "Epoch 55: train RMSE 23.0693, test RMSE 22.9631\n",
            "Epoch 56: train RMSE 23.0103, test RMSE 22.9256\n",
            "Epoch 57: train RMSE 23.0675, test RMSE 22.8076\n",
            "Epoch 58: train RMSE 23.0703, test RMSE 22.7855\n",
            "Epoch 59: train RMSE 23.0113, test RMSE 22.8520\n",
            "Epoch 60: train RMSE 23.0973, test RMSE 23.0308\n",
            "Epoch 61: train RMSE 22.9710, test RMSE 22.8849\n",
            "Epoch 62: train RMSE 23.1064, test RMSE 22.7638\n",
            "Epoch 63: train RMSE 23.1328, test RMSE 22.9706\n",
            "Epoch 64: train RMSE 23.0884, test RMSE 23.0250\n",
            "Epoch 65: train RMSE 23.0693, test RMSE 22.7300\n",
            "Epoch 66: train RMSE 22.9503, test RMSE 22.8521\n",
            "Epoch 67: train RMSE 22.9930, test RMSE 22.8083\n",
            "Epoch 68: train RMSE 22.9500, test RMSE 22.7955\n",
            "Epoch 69: train RMSE 22.9640, test RMSE 22.8813\n",
            "Epoch 70: train RMSE 22.8758, test RMSE 22.8801\n",
            "Epoch 71: train RMSE 22.9409, test RMSE 23.0708\n",
            "Epoch 72: train RMSE 22.9236, test RMSE 22.8538\n",
            "Epoch 73: train RMSE 22.9766, test RMSE 22.7092\n",
            "Epoch 74: train RMSE 22.9035, test RMSE 22.8530\n",
            "Epoch 75: train RMSE 22.9047, test RMSE 22.9997\n",
            "Epoch 76: train RMSE 22.8822, test RMSE 22.6707\n",
            "Epoch 77: train RMSE 22.8489, test RMSE 22.8072\n",
            "Epoch 78: train RMSE 22.8600, test RMSE 22.8111\n",
            "Epoch 79: train RMSE 22.9793, test RMSE 23.1364\n",
            "Epoch 80: train RMSE 22.7364, test RMSE 22.7577\n",
            "Epoch 81: train RMSE 22.8464, test RMSE 22.7479\n",
            "Epoch 82: train RMSE 22.7901, test RMSE 22.8099\n",
            "Epoch 83: train RMSE 22.8099, test RMSE 22.8874\n",
            "Epoch 84: train RMSE 22.8587, test RMSE 22.9183\n",
            "Epoch 85: train RMSE 22.8813, test RMSE 22.9930\n",
            "Epoch 86: train RMSE 22.7509, test RMSE 22.8192\n",
            "Epoch 87: train RMSE 22.7225, test RMSE 22.7955\n",
            "Epoch 88: train RMSE 22.7990, test RMSE 22.8986\n",
            "Epoch 89: train RMSE 22.7764, test RMSE 22.8697\n",
            "Epoch 90: train RMSE 22.6844, test RMSE 22.8347\n",
            "Epoch 91: train RMSE 22.6669, test RMSE 22.8182\n",
            "Epoch 92: train RMSE 22.6776, test RMSE 22.6964\n",
            "Epoch 93: train RMSE 22.7306, test RMSE 22.9793\n",
            "Epoch 94: train RMSE 22.6305, test RMSE 22.7999\n",
            "Epoch 95: train RMSE 22.7112, test RMSE 22.8798\n",
            "Epoch 96: train RMSE 22.6566, test RMSE 22.8286\n",
            "Epoch 97: train RMSE 22.6851, test RMSE 22.8323\n",
            "Epoch 98: train RMSE 22.6183, test RMSE 22.8764\n",
            "Epoch 99: train RMSE 22.6118, test RMSE 22.7845\n",
            "Epoch 0: train RMSE 58.1178, test RMSE 59.4017\n",
            "Epoch 1: train RMSE 50.5081, test RMSE 51.6358\n",
            "Epoch 2: train RMSE 45.9294, test RMSE 46.4794\n",
            "Epoch 3: train RMSE 42.6781, test RMSE 42.6829\n",
            "Epoch 4: train RMSE 40.0233, test RMSE 39.4637\n",
            "Epoch 5: train RMSE 37.8475, test RMSE 36.7702\n",
            "Epoch 6: train RMSE 36.0080, test RMSE 34.4739\n",
            "Epoch 7: train RMSE 34.4501, test RMSE 32.5555\n",
            "Epoch 8: train RMSE 33.2998, test RMSE 31.1835\n",
            "Epoch 9: train RMSE 32.1328, test RMSE 29.7651\n",
            "Epoch 10: train RMSE 31.2850, test RMSE 28.9285\n",
            "Epoch 11: train RMSE 30.6234, test RMSE 28.0750\n",
            "Epoch 12: train RMSE 30.0553, test RMSE 27.5512\n",
            "Epoch 13: train RMSE 29.5199, test RMSE 27.1391\n",
            "Epoch 14: train RMSE 29.1540, test RMSE 26.7719\n",
            "Epoch 15: train RMSE 28.8307, test RMSE 26.5480\n",
            "Epoch 16: train RMSE 28.5642, test RMSE 26.3193\n",
            "Epoch 17: train RMSE 28.3731, test RMSE 26.2382\n",
            "Epoch 18: train RMSE 28.2392, test RMSE 26.1592\n",
            "Epoch 19: train RMSE 28.1265, test RMSE 26.0247\n",
            "Epoch 20: train RMSE 27.9329, test RMSE 25.9422\n",
            "Epoch 21: train RMSE 27.8486, test RMSE 25.9352\n",
            "Epoch 22: train RMSE 27.7407, test RMSE 25.8119\n",
            "Epoch 23: train RMSE 27.6098, test RMSE 25.7584\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-157-fbd70c4cc66b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m           \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tensor_11_train = pd.DataFrame(torch.cat(tuple(stat_train_predictions), axis=1).numpy())\n",
        "df_tensor_11_test = pd.DataFrame(torch.cat(tuple(stat_test_predictions), axis=1).numpy())"
      ],
      "metadata": {
        "id": "tppW5p8s7iFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = torch.tensor(list(G.edges())).t().contiguous()\n",
        "\n",
        "# change x to have stat train and test predictions\n",
        "x = torch.tensor([[df_tensor_11_train['Value'].values(), ] for df in data_frames], dtype=torch.float)\n",
        "\n",
        "# this one is the targets, which I think is right rn\n",
        "targets = torch.tensor([df[['Value']].values for df in data_frames], dtype=torch.float)\n",
        "data = Data(x=x, edge_index=edge_index, y=targets)\n",
        "num_nodes = data.num_nodes\n",
        "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "train_size = int(num_nodes * 0.8)\n",
        "train_mask[:train_size] = True\n",
        "test_mask[train_size:] = True\n",
        "data.train_mask = train_mask\n",
        "data.test_mask = test_mask\n",
        "\n",
        "class BasicGNN(torch.nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(BasicGNN, self).__init__()\n",
        "        self.conv1 = SAGEConv(num_features, 16)\n",
        "        self.conv2 = SAGEConv(16, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x.squeeze()\n",
        "\n",
        "model = BasicGNN(num_features=2)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "for epoch in range(2000):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Gl30XSK9Iu8H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}