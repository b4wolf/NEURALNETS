{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def filter_wisconsin_rows(input_csv, output_csv):\n",
    "    chunk_size = 10000  \n",
    "    first_chunk = True  \n",
    "    for chunk in pd.read_csv(input_csv, chunksize=chunk_size):\n",
    "        filtered_chunk = chunk[chunk['State Name'] == 'Wisconsin']\n",
    "        if not filtered_chunk.empty:\n",
    "            filtered_chunk.to_csv(output_csv, mode='a', header=first_chunk, index=False)\n",
    "            first_chunk = False\n",
    "            \n",
    "\n",
    "# Usage\n",
    "input_file = 'hourly_88101_2020.csv'\n",
    "output_file = 'filtered_wisconsin.csv'\n",
    "filter_wisconsin_rows(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ff6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filtered_wisconsin.csv', error_bad_lines=False)\n",
    "df = df[['State Code','County Code','County Code','Parameter Code','Latitude','Longitude','Date Local','Time Local','Date GMT','Time GMT','Sample Measurement','County Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71669ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_wi_2020_pm25', mode='a', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "milwaukee_df = df[df['County Name'] == 'Milwaukee']\n",
    "unique_lat_lon = milwaukee_df[['Latitude', 'Longitude']].drop_duplicates().iloc[0]\n",
    "# Filter the DataFrame to only include rows with this lat/lon pair\n",
    "filtered_df = milwaukee_df[(milwaukee_df['Latitude'] == unique_lat_lon['Latitude']) & (milwaukee_df['Longitude'] == unique_lat_lon['Longitude'])]\n",
    "# Now filtered_df contains rows for Milwaukee County with a single lat/lon pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c794d",
   "metadata": {},
   "source": [
    "# Use this function to split a CSV by date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af29a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_csv_on_date_change(input_csv):\n",
    "    \"\"\"\n",
    "    Splits a CSV file into multiple new CSV files each time the date format in 'Date Local' changes.\n",
    "\n",
    "    Parameters:\n",
    "    - input_csv (str): The path to the input CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    current_format = None\n",
    "    start_index = 0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        date_local = row['Date Local']\n",
    "        new_format = '-' in date_local\n",
    "\n",
    "        if current_format is None:\n",
    "            current_format = new_format\n",
    "        elif current_format != new_format:\n",
    "            # Date format changed, split and save the DataFrame up to the current row\n",
    "            df_slice = df.iloc[start_index:i]\n",
    "            output_file = f'split_{start_index}_{i-1}.csv'\n",
    "            df_slice.to_csv(output_file, index=False)\n",
    "            start_index = i\n",
    "            current_format = new_format\n",
    "\n",
    "    # Save the last slice\n",
    "    if start_index < len(df):\n",
    "        output_file = f'split_{start_index}_{len(df)-1}.csv'\n",
    "        df.iloc[start_index:].to_csv(output_file, index=False)\n",
    "\n",
    "# Usage\n",
    "input_csv = 'filtered_wisconsin_1_pm10.csv'\n",
    "split_csv_on_date_change(input_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aaa174",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'hourly_81102_2020.csv'\n",
    "output_file = 'cleaned_MKE_2020_pm10.csv'\n",
    "filter_wisconsin_rows(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c5bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filtered_wisconsin_1_pm10.csv', error_bad_lines=False)\n",
    "df = df[['State Code','County Code','County Code','Parameter Code','Latitude','Longitude','Date Local','Time Local','Date GMT','Time GMT','Parameter Name','Sample Measurement','County Name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad0e433",
   "metadata": {},
   "source": [
    "# Use this to find differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5041d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "def find_nearest(df, lat, lon):\n",
    "    distances = df.apply(lambda row: haversine_distance(lat, lon, row['Latitude'], row['Longitude']), axis=1)\n",
    "    min_distance_index = distances.idxmin()\n",
    "    return df.loc[[min_distance_index]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f766a8",
   "metadata": {},
   "source": [
    "# Check SO2 lat example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95e811",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = 'hourly_42401_2020.csv'\n",
    "output_file = 'filtered_wisconsin_1_so2.csv'\n",
    "filter_wisconsin_rows(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filtered_wisconsin_1_so2.csv', error_bad_lines=False)\n",
    "df = df[['State Code','County Code','County Code','Parameter Code','Latitude','Longitude','Date Local','Time Local','Date GMT','Time GMT','Parameter Name','Sample Measurement','County Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_df = find_nearest(df, input_latitude, input_longitude)\n",
    "nearest_df['Latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73826c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched = df[df['Latitude'] == 43.060975]\n",
    "df_matched.to_csv('cleaned_MKE_2020_so2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
